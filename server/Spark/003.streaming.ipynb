{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff867267-cd24-4269-9193-2227c5c1cf13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# SPARK STREAMING\n",
    "\n",
    "Aache Spark Streaming es un componente del ecosistema Apache Spark diseñado específicamente para el procesamiento de datos en tiempo real y el análisis de datos de flujo continuo. Permite a los desarrolladores y analistas de datos procesar datos en tiempo real de manera escalable, tolerante a fallos y de alto rendimiento utilizando el modelo de programación familiar de Apache Spark.\n",
    "\n",
    "Para hacer esta demo, realizar los siguientes pasos:\n",
    "\n",
    "1. Tener la imagen de spark corriendo y el contenedor anclado el VScode\n",
    "2. abrir una terminal, y ejecutar `nc -l -k 12345`\n",
    "3. ir al notebook y ejecutar todas las secuencias de spark\n",
    "4. volver a la consola y enviar mensajes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca8173d-6bfe-4ff8-b5c9-62dad2df49d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## CONFIGURAR SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea7122ce-c14d-4f86-8f72-a47ce9e6c5af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"unal streaming\") \\\n",
    "  .master(\"local[*]\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5031ca-22c4-49bc-bf96-0772b8b6563e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## CONFIGURAR FUENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5959abe-6cfd-44d0-b8c9-19d749cde238",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_df = spark.readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", \"12345\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18b1ee73-48ca-4211-abff-c769dfc45ff9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## CONFIGURAR FUNCION DE TRANSFORMACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08564f9d-4338-444d-8a47-dcb15a871954",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# funcion para realizar transformaciones\n",
    "def process_word_count(streaming_df):\n",
    "    # lee y aplica transformacion\n",
    "    words_df = streaming_df.selectExpr(\"explode(split(value, ' ')) as word\")\n",
    "\n",
    "    # Arealiza proceso de agregación\n",
    "    agg_words_df = words_df \\\n",
    "        .groupBy(\"word\") \\\n",
    "        .agg(count(\"word\").alias(\"count\"))\n",
    "    \n",
    "    # imprimir esquema\n",
    "    agg_words_df.printSchema()\n",
    "    return agg_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f779dd9e-a5c8-4c45-944e-39ac289a1d64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### ALMACENAMIENTO\n",
    "\n",
    "para ver como configurar mas destinos, mirar:\n",
    "\n",
    "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37b93a92-d6a2-44ae-b5fb-ac1798b138cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lee y transforma\n",
    "agg_words_df = process_word_count(streaming_df)\n",
    "\n",
    "# escritura en consola\n",
    "writing_df = agg_words_df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .start()\n",
    "\n",
    "# de este modo, se ejecuta \n",
    "writing_df.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3470490410964087,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "003.streaming",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
